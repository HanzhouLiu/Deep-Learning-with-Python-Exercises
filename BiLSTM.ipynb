{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaFG30n5v46Q5H4tJPfWHn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanzhouLiu/Deep-Learning-with-Python-Exercises/blob/main/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yspv9iYmPojS"
      },
      "source": [
        "# Design, train and test a neural network model for the IMDB dataset, using bidirectional LSTM\r\n",
        "from __future__ import print_function\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from keras.preprocessing import sequence\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\r\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\r\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cohuoddP8gd"
      },
      "source": [
        "max_features = 2000\r\n",
        "# cut texts after this number of words\r\n",
        "# (among top max_features most common words)\r\n",
        "maxlen = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gA_CkVIP_AG",
        "outputId": "ef3f1df5-c865-4ad5-c38e-d8858890730e"
      },
      "source": [
        "print('Loading data...')\r\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\r\n",
        "print(len(x_train), 'train sequences')\r\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9efuixVQKWK",
        "outputId": "c0cf7c1f-ba0c-4802-e8f2-5336d34a2710"
      },
      "source": [
        "print('Pad sequences (samples x time)')\r\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\r\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print('x_test shape:', x_test.shape)\r\n",
        "y_train = np.array(y_train)\r\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ1dLZZsQPPb"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\r\n",
        "model.add(Bidirectional(LSTM(64)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyKJs3G_QRB2"
      },
      "source": [
        "opti_ = Adam(lr=0.0025)\r\n",
        "model.compile(optimizer=opti_, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE9JhQ73QWVR",
        "outputId": "e561d00f-2107-450a-c13c-428dc3b90000"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 128)          256000    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 354,945\n",
            "Trainable params: 354,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGJspBYeQZMe"
      },
      "source": [
        "batch_size = 64\r\n",
        "epochs = 20"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAY4DvnrQb9J"
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeS0BtUjQcpo",
        "outputId": "f8d04892-2e71-44a7-cff2-a448e0c141df"
      },
      "source": [
        "t1=time()\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          validation_data=[x_test, y_test])\r\n",
        "t2=time()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 41s 20ms/step - loss: 0.5200 - accuracy: 0.7205 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.3314 - accuracy: 0.8585 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2736 - accuracy: 0.8877 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2319 - accuracy: 0.9070 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1868 - accuracy: 0.9270 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1495 - accuracy: 0.9429 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1182 - accuracy: 0.9581 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0905 - accuracy: 0.9691 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0754 - accuracy: 0.9750 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0560 - accuracy: 0.9813 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8uBE4a_Q4kT",
        "outputId": "bbca7d56-1dab-4bbf-9c7b-dd534502cfb4"
      },
      "source": [
        "t_delta = round((t2-t1)/60,3)\r\n",
        "print(f\"{epochs} took total {t_delta} minutes.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 took total 2.849 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usyEe6biRLH0"
      },
      "source": [
        "def lr_schedule(epoch):\r\n",
        "    \"\"\"Learning Rate Schedule\r\n",
        "\r\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n",
        "    Called automatically every epoch as part of callbacks during training.\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        epoch (int): The number of epochs\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        lr (float32): learning rate\r\n",
        "    \"\"\"\r\n",
        "    lr = 0.005\r\n",
        "    if epoch >= 3:\r\n",
        "        lr *= 0.5\r\n",
        "    if epoch >= 7:\r\n",
        "        lr *= 0.25\r\n",
        "    if epoch >= 11:\r\n",
        "        lr *= 0.5\r\n",
        "    if epoch >= 16:\r\n",
        "        lr *= 0.5\r\n",
        "        \r\n",
        "    print('Learning rate: ', lr)\r\n",
        "    return lr"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMH6BUB_ROF7",
        "outputId": "ecfd1a99-50d8-4460-d07a-49eb4cacd36c"
      },
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "callbacks = [lr_reducer, lr_scheduler]\r\n",
        "#callbacks = [lr_scheduler]\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\r\n",
        "model.add(Bidirectional(LSTM(64)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "opti_ = Adam(lr=lr_schedule(0))\r\n",
        "model.compile(optimizer=opti_, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "t1=time()\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          validation_data=[x_test, y_test],\r\n",
        "          callbacks=callbacks)\r\n",
        "t2=time()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.005\n",
            "Epoch 1/20\n",
            "Learning rate:  0.005\n",
            "391/391 [==============================] - 10s 19ms/step - loss: 0.5378 - accuracy: 0.7065 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "Learning rate:  0.005\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3663 - accuracy: 0.8414 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "Learning rate:  0.005\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3150 - accuracy: 0.8675 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "Learning rate:  0.0025\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2333 - accuracy: 0.9039 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "Learning rate:  0.0025\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1892 - accuracy: 0.9245 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "Learning rate:  0.0025\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1442 - accuracy: 0.9456 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "Learning rate:  0.0025\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1167 - accuracy: 0.9582 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "Learning rate:  0.000625\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0734 - accuracy: 0.9769 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "Learning rate:  0.000625\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "Learning rate:  0.000625\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "Learning rate:  0.000625\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "Learning rate:  0.0003125\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0205 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "Learning rate:  0.0003125\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0166 - accuracy: 0.9967 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "Learning rate:  0.0003125\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "Learning rate:  0.0003125\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "Learning rate:  0.0003125\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "Learning rate:  0.00015625\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "Learning rate:  0.00015625\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "Learning rate:  0.00015625\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "Learning rate:  0.00015625\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}